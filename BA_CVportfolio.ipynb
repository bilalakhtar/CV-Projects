{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86991bc6-4e6d-4940-9b10-696bd90a7c76",
   "metadata": {},
   "source": [
    "# Portfolio Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e7e8b8-ab1f-460a-98a4-89161cba9897",
   "metadata": {},
   "source": [
    "### 1. Experiment Setup\n",
    "\n",
    "#### Libraries\n",
    "#### First, import necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a15c6be4-3566-4af0-98ae-1680e4563452",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b67cc737-4739-4751-a7f8-2077ff4cef11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3bd236-4c04-4039-8690-3991739996ad",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb6cbcd9-aa57-431e-a337-0b74338394c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'path_to_your_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m\n\u001b[0;32m      5\u001b[0m train_datagen \u001b[38;5;241m=\u001b[39m ImageDataGenerator(rescale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255\u001b[39m, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.15\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m train_generator \u001b[38;5;241m=\u001b[39m train_datagen\u001b[38;5;241m.\u001b[39mflow_from_directory(\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath_to_your_data\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      9\u001b[0m     target_size\u001b[38;5;241m=\u001b[39mimg_size,\n\u001b[0;32m     10\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m     11\u001b[0m     class_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     12\u001b[0m     subset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     14\u001b[0m validation_generator \u001b[38;5;241m=\u001b[39m train_datagen\u001b[38;5;241m.\u001b[39mflow_from_directory(\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath_to_your_data\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     16\u001b[0m     target_size\u001b[38;5;241m=\u001b[39mimg_size,\n\u001b[0;32m     17\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m     18\u001b[0m     class_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     19\u001b[0m     subset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Class labels\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:1138\u001b[0m, in \u001b[0;36mImageDataGenerator.flow_from_directory\u001b[1;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflow_from_directory\u001b[39m(\n\u001b[0;32m   1121\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1122\u001b[0m     directory,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1136\u001b[0m     keep_aspect_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1137\u001b[0m ):\n\u001b[1;32m-> 1138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DirectoryIterator(\n\u001b[0;32m   1139\u001b[0m         directory,\n\u001b[0;32m   1140\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1141\u001b[0m         target_size\u001b[38;5;241m=\u001b[39mtarget_size,\n\u001b[0;32m   1142\u001b[0m         color_mode\u001b[38;5;241m=\u001b[39mcolor_mode,\n\u001b[0;32m   1143\u001b[0m         keep_aspect_ratio\u001b[38;5;241m=\u001b[39mkeep_aspect_ratio,\n\u001b[0;32m   1144\u001b[0m         classes\u001b[38;5;241m=\u001b[39mclasses,\n\u001b[0;32m   1145\u001b[0m         class_mode\u001b[38;5;241m=\u001b[39mclass_mode,\n\u001b[0;32m   1146\u001b[0m         data_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_format,\n\u001b[0;32m   1147\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1148\u001b[0m         shuffle\u001b[38;5;241m=\u001b[39mshuffle,\n\u001b[0;32m   1149\u001b[0m         seed\u001b[38;5;241m=\u001b[39mseed,\n\u001b[0;32m   1150\u001b[0m         save_to_dir\u001b[38;5;241m=\u001b[39msave_to_dir,\n\u001b[0;32m   1151\u001b[0m         save_prefix\u001b[38;5;241m=\u001b[39msave_prefix,\n\u001b[0;32m   1152\u001b[0m         save_format\u001b[38;5;241m=\u001b[39msave_format,\n\u001b[0;32m   1153\u001b[0m         follow_links\u001b[38;5;241m=\u001b[39mfollow_links,\n\u001b[0;32m   1154\u001b[0m         subset\u001b[38;5;241m=\u001b[39msubset,\n\u001b[0;32m   1155\u001b[0m         interpolation\u001b[38;5;241m=\u001b[39minterpolation,\n\u001b[0;32m   1156\u001b[0m         dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[0;32m   1157\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:453\u001b[0m, in \u001b[0;36mDirectoryIterator.__init__\u001b[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m classes:\n\u001b[0;32m    452\u001b[0m     classes \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 453\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m subdir \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(directory)):\n\u001b[0;32m    454\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, subdir)):\n\u001b[0;32m    455\u001b[0m             classes\u001b[38;5;241m.\u001b[39mappend(subdir)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'path_to_your_data'"
     ]
    }
   ],
   "source": [
    "# Image preprocessing (resizing, rescaling)\n",
    "img_size = (224, 224)\n",
    "batch_size = 32\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.15)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'path_to_your_data',\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training')\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    'path_to_your_data',\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation')\n",
    "\n",
    "# Class labels\n",
    "class_labels = list(train_generator.class_indices.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bd4c57-9952-4211-9959-cfad01172ace",
   "metadata": {},
   "source": [
    "### 2. Custom CNN Architecture\n",
    "#### Define a simple CNN model for image classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32fd32be-441e-4b67-871b-271b85032a34",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Get input shape and number of classes\u001b[39;00m\n\u001b[0;32m     29\u001b[0m input_shape \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m---> 30\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m train_generator\u001b[38;5;241m.\u001b[39mnum_classes\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Build and compile model\u001b[39;00m\n\u001b[0;32m     33\u001b[0m custom_cnn \u001b[38;5;241m=\u001b[39m build_custom_cnn(input_shape, num_classes)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_generator' is not defined"
     ]
    }
   ],
   "source": [
    "def build_custom_cnn(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Convolutional layers\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # Fully connected layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Get input shape and number of classes\n",
    "input_shape = (224, 224, 3)\n",
    "num_classes = train_generator.num_classes\n",
    "\n",
    "# Build and compile model\n",
    "custom_cnn = build_custom_cnn(input_shape, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8feecd8c-0a43-4c8b-b71d-281e5074962c",
   "metadata": {},
   "source": [
    "#### Training Custom CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3a402f-2116-411c-bf8d-f19113ac6893",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_custom = custom_cnn.fit(train_generator,\n",
    "                                epochs=10,\n",
    "                                validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ddffa2-4163-4c21-8c23-7e22bf8e87a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c62b59f4-9cb0-4129-98eb-79bc381d3b96",
   "metadata": {},
   "source": [
    "### 3. Transfer Learning with Pre-Trained Model\n",
    "#### Use VGG16 for transfer learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7554b450-d5fd-4e2c-82ab-f5c5ef95429e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_transfer_model(input_shape, num_classes):\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    \n",
    "    # Freeze the base model\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # Add custom layers on top\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Build transfer learning model\n",
    "transfer_model = build_transfer_model(input_shape, num_classes)\n",
    "\n",
    "# Train the model\n",
    "history_transfer = transfer_model.fit(train_generator,\n",
    "                                      epochs=10,\n",
    "                                      validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541e96fe-0af0-49eb-9abe-397f5f1fe13d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6770c5a-76fd-4f6f-88da-62a34c444051",
   "metadata": {},
   "source": [
    "### 4. Evaluation\n",
    "#### Custom CNN Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b158af64-5e7c-4d03-9273-3d893e53534b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate custom CNN on validation data\n",
    "custom_eval = custom_cnn.evaluate(validation_generator)\n",
    "print(f\"Custom CNN Accuracy: {custom_eval[1]*100:.2f}%\")\n",
    "\n",
    "# Predictions and classification report\n",
    "pred_custom = custom_cnn.predict(validation_generator)\n",
    "pred_custom_labels = np.argmax(pred_custom, axis=1)\n",
    "print(classification_report(validation_generator.classes, pred_custom_labels, target_names=class_labels))\n",
    "\n",
    "# Confusion matrix\n",
    "cm_custom = confusion_matrix(validation_generator.classes, pred_custom_labels)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm_custom, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.title('Confusion Matrix - Custom CNN')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083cdae3-42c3-4448-8c62-757a6d0c4023",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4e4c7d7-8802-4eb4-8e16-c80b2a78c599",
   "metadata": {},
   "source": [
    "#### Transfer Learning Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9233b3-37ef-4c07-8034-42a61aac15dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate transfer model on validation data\n",
    "transfer_eval = transfer_model.evaluate(validation_generator)\n",
    "print(f\"Transfer Learning Accuracy: {transfer_eval[1]*100:.2f}%\")\n",
    "\n",
    "# Predictions and classification report\n",
    "pred_transfer = transfer_model.predict(validation_generator)\n",
    "pred_transfer_labels = np.argmax(pred_transfer, axis=1)\n",
    "print(classification_report(validation_generator.classes, pred_transfer_labels, target_names=class_labels))\n",
    "\n",
    "# Confusion matrix\n",
    "cm_transfer = confusion_matrix(validation_generator.classes, pred_transfer_labels)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm_transfer, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.title('Confusion Matrix - Transfer Learning')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff5f4f1-e30e-4509-a8a2-af2338b251dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71ae91a-7dc5-4320-a4d8-2988f6c9809a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf21ef7-ba9e-443b-acaa-37cea1c12dfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14889792-40b3-42ef-810d-d6c7945f3d6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c03aec-d705-46a0-a525-2644ed83e15e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d897d4c7-eff3-41d9-884c-b521bb82ec0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f44e56c-6fb3-4f45-8eeb-914f778c02a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58881a3-faef-4f70-bf48-ed3a1525482b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4fae06-ca17-438b-835c-319a784264f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191316ce-861d-41a2-b1b9-63e521648863",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cee4a8f-b1c3-4e55-9764-e1b3a63c7578",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
